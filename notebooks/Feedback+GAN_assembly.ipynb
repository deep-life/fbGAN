{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feedback+GAN assembly.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm6a8Ch9krFF"
      },
      "source": [
        "# Imports + Globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNAHtAivmwwu",
        "outputId": "db9fabca-8759-4dc0-b09b-4ff7df167acb"
      },
      "source": [
        "MAX_LEN = 243\n",
        "MIN_LEN = 0\n",
        "\n",
        "TASK_TYPE = 'DNA'\n",
        "MAX_LEN_PROTEIN = MAX_LEN // 3 - 6\n",
        "MIN_LEN_PROTEIN = MIN_LEN // 3 - 6\n",
        "print(f'Protein length: {MAX_LEN_PROTEIN}')\n",
        "\n",
        "SEQ_LENGTH = MAX_LEN\n",
        "DIM = 50\n",
        "KERNEL_SIZE = 5\n",
        "BATCH_SIZE = 128\n",
        "N_CHAR = 5\n",
        "NOISE_SHAPE = 128\n",
        "\n",
        "# Check for RAM capacity purposes\n",
        "print(f'RESOURCE: {SEQ_LENGTH * DIM}')\n",
        "\n",
        "\n",
        "# SELECT PATH\n",
        "# for protein sequences\n",
        "path = '/content/gdrive/My Drive/protein_cleaned.csv'\n",
        "# path for fbgan history\n",
        "LOSS_PATH = '/content/gdrive/My Drive/CS496 final project/FBGAN-history/loss.csv'\n",
        "BEST_PATH = '/content/gdrive/My Drive/CS496 final project/FBGAN-history/best.csv'\n",
        "AVERAGE_PATH = '/content/gdrive/My Drive/CS496 final project/FBGAN-history/average.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Protein length: 75\n",
            "RESOURCE: 12150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTJPtlGckcZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb22af5-e248-4433-f761-91388d063889"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras.utils import to_categorical\n",
        "import seaborn as sns\n",
        "from matplotlib import rc\n",
        "import matplotlib as plt\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Model, Input\n",
        "from tensorflow.keras.layers import Conv1D,Input,Dense, Reshape, ReLU, Permute,Softmax, LSTM, Embedding, Dense, TimeDistributed, Bidirectional, LayerNormalization\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "sns.set_context(\"paper\")\n",
        "sns.color_palette(\"cubehelix\", 8)\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "# Using seaborn's style\n",
        "plt.style.use('seaborn')\n",
        "# With LaTex fonts\n",
        "sns.set_context(\"paper\")\n",
        "\n",
        "\n",
        "# Set the global font to be DejaVu Sans, size 10 (or any other sans-serif font of your choice!)\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['DejaVu Sans'],'size':9})\n",
        "\n",
        "# Set the font used for MathJax - more on this later\n",
        "rc('mathtext',**{'default':'regular'})\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjNu_OJZrHGI"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1NLxBNmrLV1"
      },
      "source": [
        "from matplotlib import rc\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_context(\"paper\")\n",
        "sns.set_palette(\"husl\", 5)\n",
        "\n",
        "\n",
        "# Set the global font to be DejaVu Sans, size 10 (or any other sans-serif font of your choice!)\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['DejaVu Sans'],'size':9})\n",
        "\n",
        "# Set the font used for MathJax - more on this later\n",
        "rc('mathtext',**{'default':'regular'})\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "\n",
        "def plot_history(history,name,metrics):\n",
        "\n",
        "  fig, axs = plt.subplots(len(metrics)//2,figsize=(10,15))\n",
        "  plt.subplots_adjust(hspace=0.4)\n",
        "  fig.suptitle(name)\n",
        "  # summarize history for each metric\n",
        "  for i,metric in enumerate(metrics[:4]):\n",
        "    #first half of metric dictionary is train, second half - validation\n",
        "    axs[i].plot(history.history[metric])\n",
        "    axs[i].plot(history.history['val_'+metric])\n",
        "    if metric == 'loss':\n",
        "      metric = 'binary_crossentropy'\n",
        "    axs[i].set_title('model`s ' + metric)\n",
        "    axs[i].set_ylabel(metric)\n",
        "    axs[i].set_xlabel('epoch')\n",
        "    axs[i].legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyP5pX1K0YYL"
      },
      "source": [
        "## Data misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_49ca4Z60an6"
      },
      "source": [
        "DNA_protein_MAP = {\n",
        "            'ATA': 'I', 'ATC': 'I', 'ATT': 'I', 'ATG': 'M',\n",
        "            'ACA': 'T', 'ACC': 'T', 'ACG': 'T', 'ACT': 'T',\n",
        "            'AAC': 'N', 'AAT': 'N', 'AAA': 'K', 'AAG': 'K',\n",
        "            'AGC': 'S', 'AGT': 'S', 'AGA': 'R', 'AGG': 'R',\n",
        "            'CTA': 'L', 'CTC': 'L', 'CTG': 'L', 'CTT': 'L',\n",
        "            'CCA': 'P', 'CCC': 'P', 'CCG': 'P', 'CCT': 'P',\n",
        "            'CAC': 'H', 'CAT': 'H', 'CAA': 'Q', 'CAG': 'Q',\n",
        "            'CGA': 'R', 'CGC': 'R', 'CGG': 'R', 'CGT': 'R',\n",
        "            'GTA': 'V', 'GTC': 'V', 'GTG': 'V', 'GTT': 'V',\n",
        "            'GCA': 'A', 'GCC': 'A', 'GCG': 'A', 'GCT': 'A',\n",
        "            'GAC': 'D', 'GAT': 'D', 'GAA': 'E', 'GAG': 'E',\n",
        "            'GGA': 'G', 'GGC': 'G', 'GGG': 'G', 'GGT': 'G',\n",
        "            'TCA': 'S', 'TCC': 'S', 'TCG': 'S', 'TCT': 'S',\n",
        "            'TTC': 'F', 'TTT': 'F', 'TTA': 'L', 'TTG': 'L',\n",
        "            'TAC': 'Y', 'TAT': 'Y', 'TAA': 'P', 'TAG': 'P',\n",
        "            'TGC': 'C', 'TGT': 'C', 'TGA': 'P', 'TGG': 'W',\n",
        "        }\n",
        "\n",
        "protein_DNA_MAP = {v: k for k, v in DNA_protein_MAP.items()}\n",
        "protein_DNA_MAP['P'] = 'TAG'\n",
        "\n",
        "\n",
        "def protein_to_DNA(protein_sequences):\n",
        "    global protein_DNA_MAP\n",
        "\n",
        "    parsed = parse(protein_sequences)\n",
        "\n",
        "    DNA_sequences = []\n",
        " \n",
        "    if type(parsed[0]) in (str, np.str_):\n",
        "        DNA_merged = ''.join([a for a in parsed])\n",
        "        DNA_sequences += ['ATG'  +  DNA_merged + \"TAG\"]\n",
        "        return DNA_sequences\n",
        "\n",
        "    for seq in parsed:\n",
        "        DNA = [protein_DNA_MAP[a] for a in seq]\n",
        "        DNA_merged = ''.join([a for a in DNA])\n",
        "        DNA_sequences += ['ATG'  +  DNA_merged + \"TAG\"]\n",
        "\n",
        "    DNA_sequences = np.array(DNA_sequences).reshape(-1,1)\n",
        "    return DNA_sequences\n",
        "\n",
        "def parse(sequences):\n",
        "    if type(sequences) == str:\n",
        "        parsed = np.array([a for a in sequences])\n",
        "        return parsed\n",
        "\n",
        "    parse = lambda seq: np.array([a for a in seq])\n",
        "    parsed = pd.DataFrame(sequences).iloc[:,0].apply(parse).to_numpy()\n",
        "\n",
        "    return parsed\n",
        "\n",
        "def translate(seq): \n",
        "       \n",
        "    table = { \n",
        "        'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M', \n",
        "        'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T', \n",
        "        'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K', \n",
        "        'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',                  \n",
        "        'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L', \n",
        "        'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P', \n",
        "        'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q', \n",
        "        'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R', \n",
        "        'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V', \n",
        "        'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A', \n",
        "        'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E', \n",
        "        'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G', \n",
        "        'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S', \n",
        "        'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L', \n",
        "        'TAC':'Y', 'TAT':'Y', 'TAA':'', 'TAG':'', \n",
        "        'TGC':'C', 'TGT':'C', 'TGA':'', 'TGG':'W', \n",
        "    } \n",
        "    protein =\"\" \n",
        "    seq = seq[0].split('P')[0]\n",
        "    for i in range(0, len(seq), 3): \n",
        "      try:\n",
        "        codon = seq[i:i + 3] \n",
        "        protein+= table[codon] \n",
        "      except:\n",
        "        protein+= \"\"\n",
        "    return protein\n",
        "\n",
        "def DNA_to_protein(sequences):\n",
        "    result = []\n",
        "    for seq in sequences:\n",
        "      result.append(translate(seq))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ule64wh8xSJ"
      },
      "source": [
        "class OneHot_Seq:\n",
        "    def __init__(self, letter_type='amino acids', letters = None, max_length=MAX_LEN):\n",
        "        \"\"\"\n",
        "        :param letter_type: str 'amino acids' or 'DNA'. If a different type is used, provide custom letters.\n",
        "        :param max_length: int maximum length of a sequence. Sequences will be padded to this length.\n",
        "        \"\"\"\n",
        "\n",
        "        if letter_type == 'amino acids':\n",
        "            self.letters = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T',\n",
        "                            'W', 'Y', 'V']\n",
        "        elif letter_type == 'DNA':\n",
        "            self.letters = ['A', 'T', 'C', 'G']\n",
        "\n",
        "        else:\n",
        "            assert letters is not None\n",
        "            self.letters = letters\n",
        "\n",
        "        self.letters_dict = {f'{aa}': i + 1 for i, aa in enumerate(self.letters)}\n",
        "        self.invert_dict = {v: k for k, v in self.letters_dict.items()}\n",
        "        self.invert_dict[0] = 'P'\n",
        "\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def _parse_pad_sequences(self, sequences):\n",
        "\n",
        "        parse = lambda seq: np.array([a for a in seq])\n",
        "        parsed = pd.DataFrame(sequences).iloc[:, 0].apply(parse)\n",
        "\n",
        "        for i in range(parsed.shape[0]):\n",
        "            parsed[i] = np.vectorize(self.letters_dict.get)(parsed[i])\n",
        "\n",
        "        parsed = pad_sequences(parsed, maxlen=self.max_length, value=0, padding='post')\n",
        "\n",
        "        return parsed\n",
        "\n",
        "    def seq_to_onehot(self, sequences):\n",
        "        \"\"\"\n",
        "        Return an array of one-hot encodings from sequence strings.\n",
        "        :param sequences: ndarray of strings, shape = (N,1) where N is the number of samples\n",
        "        :return: array of onehot encoded sequences, shape = (N, max_length, amino_acids)\n",
        "        \"\"\"\n",
        "        sequences = self._parse_pad_sequences(sequences)\n",
        "        onehot = []\n",
        "\n",
        "        for seq in sequences:\n",
        "            onehot_seq = np.zeros((seq.size, len(self.letters) + 1))\n",
        "            onehot_seq[np.arange(seq.size), seq] = 1\n",
        "            onehot.append(onehot_seq)\n",
        "\n",
        "        return np.array(onehot)\n",
        "\n",
        "    def onehot_to_seq(self, sequences):\n",
        "        \"\"\"\n",
        "        Returns an array of strings from one-hot encoding.\n",
        "        :param sequences: ndarray of shape (N, max_length, amino_acids) where N is the number of samples\n",
        "        :return: array of strings of shape (N, 1)\n",
        "        \"\"\"\n",
        "        if sequences.ndim == 2:\n",
        "            sequences = np.argmax(sequences, axis=1)\n",
        "            sequences = np.vectorize(self.invert_dict.get)(sequences)\n",
        "            decoded_sequences = [''.join([aa for aa in sequences])]\n",
        "            return decoded_sequences\n",
        "\n",
        "        sequences = np.argmax(sequences, axis=2)\n",
        "        sequences = np.vectorize(self.invert_dict.get)(sequences)\n",
        "        decoded_sequences = [[''.join([aa for aa in seq])] for seq in sequences]\n",
        "\n",
        "        return decoded_sequences\n",
        "\n",
        "def get_sequences(path, split = 0.2, min_len = MIN_LEN, max_len = MAX_LEN_PROTEIN):\n",
        "    df = pd.read_csv(path)\n",
        "    input_seqs, target_seqs = df[['seq', 'sst8']][(df.len >= min_len) & (df.len <= max_len) & (~df.has_nonstd_aa)].values.T\n",
        "    seq_train, seq_test, target_train, target_test = train_test_split(input_seqs, target_seqs, test_size= split,random_state=1)\n",
        "    \n",
        "    return seq_train,seq_test,target_train,target_test\n",
        "\n",
        "def get_dataset(sequences, batch_size = BATCH_SIZE):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(sequences)\n",
        "    dataset = dataset.shuffle(sequences.shape[0], seed=0).batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "def prepare_dataset(path, split = 0.01):\n",
        "    # Load dataset for training  FBGAN\n",
        "\n",
        "    # Load protein sequences and shuffle them\n",
        "    X_train,_, _, _ = get_sequences(path, split)\n",
        "    X_train = X_train.tolist()\n",
        "    np.random.shuffle(X_train)\n",
        "\n",
        "    print(f'Number of training samples: {len(X_train)}')\n",
        "\n",
        "    # Translate to DNA encoding\n",
        "    X = protein_to_DNA(X_train)\n",
        "    #print(f'Example of translated DNA sequences: \\n {X[:3]}')\n",
        "\n",
        "    # One Hot encode into 5 categories, ATCG and P for padded positions\n",
        "    OneHot = OneHot_Seq(letter_type= 'DNA')\n",
        "    real_sequences = OneHot.seq_to_onehot(X)\n",
        "    real_sequences\n",
        "\n",
        "    #print(f'Example of OneHot encoding of DNA sequences: {real_sequences[0]}')\n",
        "\n",
        "    return real_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4lim2UVmOsu"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAkbVNdumSrY"
      },
      "source": [
        "## ResBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9uPJLC1mQDW"
      },
      "source": [
        "def softmax(logits):\n",
        "    shape = tf.shape(logits)\n",
        "    res = tf.nn.softmax(tf.reshape(logits, [-1,N_CHAR]))\n",
        "    return tf.reshape(res, shape)\n",
        "\n",
        "class ResidualBlock(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.relu = ReLU()\n",
        "        self.conv1d_1 = Conv1D(filters=DIM, kernel_size=KERNEL_SIZE, padding='same', strides=1, activation='relu')\n",
        "        self.conv1d_2 = Conv1D(filters=DIM, kernel_size=KERNEL_SIZE, padding='same', strides=1)\n",
        "\n",
        "    def __call__(self,X,alpha = 0.3):\n",
        "        x = self.relu(X)\n",
        "        x = self.conv1d_1(x)\n",
        "        x = self.conv1d_2(x)\n",
        "        return x + alpha*x\n",
        "\n",
        "class Generator(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        implementation of Generator\n",
        "        :param input_size: size of the sequence (input noise)\n",
        "        \"\"\"\n",
        "        super(Generator, self).__init__(name='generator')\n",
        "\n",
        "        self.model = tf.keras.models.Sequential()\n",
        "        self.model.add(Input(shape = (NOISE_SHAPE,), batch_size = BATCH_SIZE))\n",
        "        self.model.add(Dense(units = DIM*SEQ_LENGTH))\n",
        "        self.model.add(Reshape((SEQ_LENGTH, DIM)))\n",
        "\n",
        "        self.model.add(ResidualBlock())\n",
        "        self.model.add(ResidualBlock())\n",
        "        self.model.add(ResidualBlock())\n",
        "        self.model.add(ResidualBlock())\n",
        "        self.model.add(ResidualBlock())\n",
        "\n",
        "        self.model.add(Conv1D(filters = N_CHAR, kernel_size = 1))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.model(inputs)\n",
        "        x = softmax(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, clip = 1):\n",
        "        \"\"\"\n",
        "        implementation of Discriminator\n",
        "        :param clip: value to which you clip the gradients (or False)\n",
        "        \"\"\"\n",
        "        super(Discriminator, self).__init__(name='discriminator')\n",
        "\n",
        "        self.model = tf.keras.models.Sequential()\n",
        "        self.model.add(Input(shape = (SEQ_LENGTH,N_CHAR), batch_size = BATCH_SIZE))\n",
        "        self.model.add(Conv1D(filters = DIM, kernel_size = 1))\n",
        "\n",
        "        self.model.add(ResidualBlock())\n",
        "        self.model.add(ResidualBlock())\n",
        "        self.model.add(ResidualBlock())\n",
        "        self.model.add(ResidualBlock())\n",
        "        self.model.add(ResidualBlock())\n",
        "\n",
        "        self.model.add(Reshape((-1,DIM*SEQ_LENGTH)))\n",
        "        self.model.add(Dense(units = DIM*SEQ_LENGTH))\n",
        "        self.model.add(Dense(units = 1))\n",
        "\n",
        "    def call(self,inputs,training = False):\n",
        "        \"\"\"\n",
        "        model's forward pass\n",
        "        :param X: input of the size [batch_size, seq_length];\n",
        "        :param training: specifies the behavior of the call;\n",
        "        :return: Y: probability of each sequences being real of shape [batch_size, 1]\n",
        "        \"\"\"\n",
        "        x = self.model(inputs)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI5e0maOmWAr"
      },
      "source": [
        "## GAN class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igu4VyzumYGa"
      },
      "source": [
        "class GAN():\n",
        "\n",
        "    def __init__(self, batch_size = BATCH_SIZE, discriminator_steps = 0, lr = 0.0002, \n",
        "                 gradient_penalty_weight = 5, generator_weights_path=None, discriminator_weights_path=None):\n",
        "        self.batch_size = batch_size\n",
        "        self.G = Generator()\n",
        "        self.D = Discriminator()\n",
        "\n",
        "        self.d_steps = discriminator_steps\n",
        "        \n",
        "        self.history = {\"G_losses\": [], \"D_losses\": [], \"gradient_penalty\": [], \"sequences\": []}\n",
        "\n",
        "        self.G_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n",
        "        self.D_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n",
        "\n",
        "        self.gp_weight = gradient_penalty_weight\n",
        "        self.step_log = None\n",
        "\n",
        "        self.checkpoint_dir = '/content/gdrive/My Drive/CS496 final project/weights/'\n",
        "\n",
        "        if generator_weights_path:\n",
        "            self.G.load_weights(generator_weights_path)\n",
        "\n",
        "        if discriminator_weights_path:\n",
        "            self.D.load_weights(discriminator_weights_path)\n",
        "\n",
        "        \n",
        "    def generate_samples(self, number=None, decoded = False):\n",
        "        if number is None:\n",
        "            number = self.batch_size\n",
        "        z = tf.random.normal([number, NOISE_SHAPE])\n",
        "        generated = self.G(z)\n",
        "        \n",
        "        if decoded:\n",
        "            OneHot = OneHot_Seq(letter_type= TASK_TYPE)\n",
        "            generated = OneHot.onehot_to_seq(generated)\n",
        "            \n",
        "        return generated\n",
        "\n",
        "    def generator_loss(self, fake_score):\n",
        "        return -tf.math.reduce_mean(fake_score)\n",
        "\n",
        "    def discriminator_loss(self, real_score, fake_score):\n",
        "        # fake_score_mean = tf.math.reduce_mean(fake_score)\n",
        "        # real_score_mean = tf.math.reduce_mean(real_score)\n",
        "        # loss = real_score_mean - fake_score_mean\n",
        "        # return, loss, fake_score_mean, real_score_mean\n",
        "        return tf.math.reduce_mean(fake_score) - tf.math.reduce_mean(real_score)\n",
        "\n",
        "    #@tf.function\n",
        "    def gradient_penalty(self, real_samples, fake_samples):\n",
        "        alpha = tf.random.normal([self.batch_size, 1, 1], 0.0, 1.0)\n",
        "        real_samples = tf.cast(real_samples, tf.float32)\n",
        "        diff = fake_samples - real_samples\n",
        "        interpolated = real_samples + alpha * diff\n",
        "\n",
        "        with tf.GradientTape() as gp_tape:\n",
        "            gp_tape.watch(interpolated)\n",
        "            pred = self.D(interpolated, training=True)\n",
        "\n",
        "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
        "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))\n",
        "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
        "        \n",
        "        return gp\n",
        "\n",
        "    #@tf.function\n",
        "    def G_train_step(self):\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_samples = self.generate_samples()\n",
        "            fake_score = self.D(fake_samples, training=True)\n",
        "            G_loss = self.generator_loss(fake_score)\n",
        "\n",
        "        G_gradients = tape.gradient(G_loss, self.G.trainable_variables)\n",
        "        self.G_optimizer.apply_gradients((zip(G_gradients, self.G.trainable_variables)))\n",
        "\n",
        "        return G_loss\n",
        "\n",
        "    #@tf.function\n",
        "    def D_train_step(self, real_samples):\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_samples = self.generate_samples()\n",
        "            real_score = self.D(real_samples, training=True)\n",
        "            fake_score = self.D(fake_samples, training=True)\n",
        "\n",
        "            D_loss = self.discriminator_loss(real_score, fake_score)\n",
        "            GP = self.gradient_penalty(real_samples, fake_samples) * self.gp_weight\n",
        "            D_loss = D_loss + GP\n",
        "\n",
        "        D_gradients = tape.gradient(D_loss, self.D.trainable_variables)\n",
        "        self.D_optimizer.apply_gradients((zip(D_gradients, self.D.trainable_variables)))\n",
        "\n",
        "        return D_loss, GP\n",
        "\n",
        "    def create_dataset(self, inputs):\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "        dataset = dataset.shuffle(inputs.shape[0], seed=0).batch(self.batch_size, drop_remainder = True)\n",
        "        return dataset\n",
        "\n",
        "\n",
        "    def train(self, inputs, epochs, step_log = 50, save_per_epochs = None):\n",
        "        n_steps = len(self.create_dataset(inputs)) * epochs\n",
        "        step = 0\n",
        "        self.step_log = step_log\n",
        "        \n",
        "        if save_per_epochs is None:\n",
        "            save_per_epochs = epochs - 1\n",
        "        \n",
        "        # Pre-train discriminator \n",
        "        print('Pretraining discriminator...')\n",
        "        for step in range(self.d_steps):\n",
        "            dataset = self.create_dataset(inputs)\n",
        "            \n",
        "            for sample_batch in dataset:\n",
        "                self.D_train_step(sample_batch)\n",
        "\n",
        "        # Train discriminator and generator\n",
        "        for epoch in range(epochs):\n",
        "            dataset = self.create_dataset(inputs)\n",
        "\n",
        "            print(f\"Epoch {epoch}/{epochs}:\")\n",
        "\n",
        "            for sample_batch in dataset:\n",
        "                G_loss = self.G_train_step()\n",
        "                D_loss, GP = self.D_train_step(sample_batch)\n",
        "                \n",
        "                if step %  self.step_log == 0:\n",
        "                    example_sequence = self.get_highest_scoring()\n",
        "                    self.history[\"G_losses\"].append(G_loss.numpy())\n",
        "                    self.history[\"D_losses\"].append(D_loss.numpy())\n",
        "                    self.history['gradient_penalty'].append(GP.numpy())\n",
        "                    self.history['sequences'].append(example_sequence)\n",
        "                    print(f'\\t Step {step}/{n_steps} \\t Generator: {G_loss.numpy()} \\t Discriminator: {D_loss.numpy()} \\t Sequence: {example_sequence}')\n",
        "                step += 1\n",
        "            \n",
        "            # if epoch % save_per_epochs == 0:\n",
        "            #     self.G.save_weights(os.path.join(self.checkpoint_dir, f'E{epoch}_Generator'))\n",
        "            #     self.D.save_weights(os.path.join(self.checkpoint_dir, f'E{epoch}_Discriminator'))\n",
        "                \n",
        "\n",
        "    def get_highest_scoring(self, num_to_generate = BATCH_SIZE, num_to_return = 1, decoded = True):\n",
        "        fake_samples = self.generate_samples(num_to_generate)\n",
        "        fake_scores = self.D(fake_samples)\n",
        "        best_indx = np.argmax(fake_scores)\n",
        "        best_seq = fake_samples[best_indx].numpy()\n",
        "\n",
        "        if decoded:\n",
        "            OneHot = OneHot_Seq(letter_type=TASK_TYPE)\n",
        "            best_seq = OneHot.onehot_to_seq(best_seq)\n",
        "\n",
        "        return best_seq\n",
        "\n",
        "    def plot_history(self):\n",
        "        D_losses = np.array(self.history['D_losses'])\n",
        "        G_losses = np.array(self.history['G_losses'])\n",
        "\n",
        "        plt.plot(np.arange(D_losses.shape[0]), D_losses, label='Discriminator loss')\n",
        "        plt.plot(np.arange(G_losses.shape[0]), G_losses, label='Generator loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel(f'Steps (x{self.step_log})')\n",
        "        plt.legend()\n",
        "        \n",
        "        plt.show()\n",
        "\n",
        "    def show_sequences_history(self):\n",
        "        sequences_history = self.history['sequences']\n",
        "        print('History of top scoring generated sequences... \\n')\n",
        "        for i in range(len(sequences_history)):\n",
        "            print(f'Step {i*self.step_log}: \\t {sequences_history[i][0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7NmerVUm60j"
      },
      "source": [
        "# Feedback Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cddm9FUnMjo"
      },
      "source": [
        "## Train from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQFGs_-onZ4q"
      },
      "source": [
        "### Get & Transform data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjFulGZ1nf61"
      },
      "source": [
        "global n_words, MAX_LEN\n",
        "MAX_LEN = 128 #length of max sequence we want to consider for training\n",
        "n_tags = 8 #number of classes in 8-state prediction\n",
        "\n",
        "\n",
        "def triplets(sequences):\n",
        "    \"\"\"\n",
        "    Apply sliding window of length 3 to each sequence in the input list\n",
        "    :param sequences: list of sequences\n",
        "    :return: numpy array of triplets for each sequence\n",
        "    Usage: Split protein sequence into triplets of aminoacids\n",
        "    \"\"\"\n",
        "    return np.array([[aminoacids[i:i+3] for i in range(len(aminoacids))] for aminoacids in sequences])\n",
        "\n",
        "def transform_sequence(seqs, tokenizer_encoder = None):\n",
        "  # transforms sequences for input into feedback net, tokenizes + adds padding\n",
        "  # if there is no given tokenizer_encoder -> initialize one and fit it on a given sequence\n",
        "  # o.w. just transform the sequence with given tokenizer\n",
        "  # returns transformed sequences + tokenizer that was fit on the input dataset\n",
        "  if not tokenizer_encoder:\n",
        "    tokenizer_encoder = Tokenizer()\n",
        "    input_grams = triplets(seqs)\n",
        "    tokenizer_encoder.fit_on_texts(input_grams)\n",
        "  transformed = tokenizer_encoder.texts_to_sequences(input_grams)\n",
        "  transformed = sequence.pad_sequences(transformed, maxlen=MAX_LEN, padding='post')\n",
        "  return transformed,tokenizer_encoder\n",
        "\n",
        "\n",
        "def get_data_for_feedback(path='/content/gdrive/My Drive/protein_structure.csv', MAX_LEN = 128):\n",
        "  df = pd.read_csv('/content/gdrive/My Drive/protein_structure.csv')\n",
        "  input_seqs, target_seqs = df[['seq', 'sst8']][(df.len <= MAX_LEN) & (~df.has_nonstd_aa)].values.T\n",
        "\n",
        "  # Transform features\n",
        "  input_data,tokenizer = transform_sequence(input_seqs)\n",
        "  #Transform targets\n",
        "  mlb = MultiLabelBinarizer()\n",
        "  target_data = mlb.fit_transform(target_seqs)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(input_data, target_data, test_size=.3, random_state=1)\n",
        "  return X_train,X_test,y_train,y_test, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqSiGBYrngTT"
      },
      "source": [
        "### Declare & train the net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv7elsmwm_jg"
      },
      "source": [
        "global n_words,save_feedback\n",
        "X_train, X_test, y_train, y_test, tokenizer = get_data_for_feedback()\n",
        "n_words = len(tokenizer.word_index) + 1\n",
        "save_feedback = \"/content/gdrive/My Drive/saved_models/multilabel_feedback\" #path where we want to save weights\n",
        "\n",
        "class Feedback():\n",
        "  def __init__(self):\n",
        "    input = Input(shape=(MAX_LEN,))\n",
        "    x = Embedding(input_dim=n_words, output_dim=128, input_length=MAX_LEN)(input)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = Bidirectional(LSTM(units=128, return_sequences=True,use_bias=True))(x)\n",
        "    x = Bidirectional(LSTM(units=128, return_sequences=True,use_bias=True))(x)\n",
        "    x = Bidirectional(LSTM(units=128,use_bias=True))(x)\n",
        "    y = Dense(n_tags, activation=\"sigmoid\")(x)\n",
        "    self.model = Model(input, y)\n",
        "  \n",
        "  def train(self,OPTIM=\"rmsprop\", LOSS='binary_crossentropy', BATCH_SIZE =128, EPOCHS = 5):\n",
        "    self.model.compile(optimizer=OPTIM, loss=LOSS, metrics=[tf.keras.metrics.Precision(), \n",
        "                                                                            tf.keras.metrics.Recall(),\n",
        "                                                                            tf.keras.metrics.Hinge()])\n",
        "    history = self.model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "                              validation_data=(X_test, y_test), verbose=1)\n",
        "    self.model.save(save_feedback)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ieosogIsdjZ"
      },
      "source": [
        "#model = Feedback()\n",
        "#history = model.train()\n",
        "#plot_history(history, \"Feedback Net for Multilabel Classification of Sequence\",list(history.history.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kms1GxFQnP3e"
      },
      "source": [
        "## Load weights for feedback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIzQ0v22wAHu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "ec382b90-77a2-4948-db64-1c89caa09c5d"
      },
      "source": [
        "save_feedback = \"/content/gdrive/My Drive/saved_models/multilabel_feedback\" #path where weights are saved\n",
        "\n",
        "Feedback = tf.keras.models.load_model(save_feedback)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'while/Tanh' has no attr named '_class'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-6a70a923d969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msave_feedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/gdrive/My Drive/saved_models/multilabel_feedback\"\u001b[0m \u001b[0;31m#path where weights are saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mFeedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_feedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m   raise IOError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   model = tf_load.load_internal(\n\u001b[0;32m--> 121\u001b[0;31m       path, options=options, loader_cls=KerasObjectLoader)\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m--> 633\u001b[0;31m                             ckpt_options)\n\u001b[0m\u001b[1;32m    634\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         raise FileNotFoundError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models_to_reconstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# Now that the node object has been fully loaded, and the checkpoint has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options)\u001b[0m\n\u001b[1;32m    120\u001b[0m     self._concrete_functions = (\n\u001b[1;32m    121\u001b[0m         function_deserialization.load_function_def_library(\n\u001b[0;32m--> 122\u001b[0;31m             meta_graph.graph_def.library))\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mload_function_def_library\u001b[0;34m(library, load_shared_name_suffix)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# import).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0mfunc_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_def_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     \u001b[0m_restore_gradient_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenamed_functions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, input_shapes)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# Add all function nodes to the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mimporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def_for_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Initialize fields specific to FuncGraph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36mimport_graph_def_for_function\u001b[0;34m(graph_def, name)\u001b[0m\n\u001b[1;32m    410\u001b[0m   \u001b[0;34m\"\"\"Like import_graph_def but does not validate colocation constraints.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m   return _import_graph_def_internal(\n\u001b[0;32m--> 412\u001b[0;31m       graph_def, validate_colocation_constraints=False, name=name)\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_import_graph_def_internal\u001b[0;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;31m# TODO(skyewm): avoid sending serialized FunctionDefs back to the TF_Graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0m_ProcessNewOps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_ProcessNewOps\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0moriginal_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mcolocation_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_GetColocationNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolocation_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mcolocation_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolocation_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_GetColocationNames\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0mcolocation_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m     \u001b[0mclass_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;31m# No _class attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2484\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t8juz-bmD_V"
      },
      "source": [
        "# Feedback GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaUco7jJmGJE"
      },
      "source": [
        "\n",
        "\n",
        "class GAN_FBNet():\n",
        "\n",
        "    def __init__(self, generator_path=None, discriminator_path=None,\n",
        "                 fbnet_path=\"/content/gdrive/My Drive/saved_models/multilabel_feedback\", features=[]):\n",
        "        self.GAN = GAN(generator_weights_path=generator_path, discriminator_weights_path=discriminator_path)\n",
        "        self.FBNet = tf.keras.models.load_model(fbnet_path)\n",
        "        _,_,_,_,self.tokenizer = get_data_for_feedback()\n",
        "        self.label_order = np.array(['B','C','E','G','H','I','S','T'])\n",
        "        self.desired_features = features\n",
        "        self.data = None\n",
        "        self.checkpoint_dir = './'\n",
        "\n",
        "    def get_scores(self, inputs):\n",
        "        # convert the DNA sequences to protein sequences\n",
        "        protein_sequence = DNA_to_protein(inputs)\n",
        "        input_grams = triplets(protein_sequence)\n",
        "        transformed = self.tokenizer.texts_to_sequences([list(i) for i in input_grams])\n",
        "        transformed = sequence.pad_sequences(transformed, maxlen=MAX_LEN, padding='post')\n",
        "        # use FBNet to grade the sequences\n",
        "        scores = self.FBNet.predict(transformed)\n",
        "        return scores\n",
        "\n",
        "    def get_score_per_feature(self, scores):\n",
        "        scores = np.array(scores)\n",
        "        avg_scores = np.rint(100*np.mean(scores, axis = 0))\n",
        "        score_per_feature = []\n",
        "        for feature in self.desired_features:\n",
        "            i = int(np.where(feature == self.label_order)[0])\n",
        "            score_i = int(avg_scores[i])\n",
        "            fscore = (feature, score_i)\n",
        "            score_per_feature.append(fscore)     \n",
        "        return score_per_feature\n",
        "    \n",
        "    def get_best_score_per_feature(self, scores):\n",
        "      #return feature-score pairs\n",
        "      score_per_feature = []\n",
        "      best_scores = np.rint(100*np.max(scores,axis=0))\n",
        "      for feature in self.desired_features:\n",
        "            i = int(np.where(feature == self.label_order)[0])\n",
        "            score_i = int(best_scores[i])\n",
        "            fscore = (feature, score_i)\n",
        "            score_per_feature.append(fscore)     \n",
        "      return score_per_feature\n",
        "\n",
        "    def add_samples(self, generated, scores, score_threshold=0.1, replace=False):\n",
        "        best_index = scores > score_threshold\n",
        "        best_samples = []\n",
        "        best_scores = []\n",
        "        for i in range(len(best_index)):\n",
        "          passed_threshold = set(self.label_order[best_index[i]])\n",
        "          if set(self.desired_features).issubset(passed_threshold):\n",
        "            best_samples.append(generated[i])\n",
        "            best_scores.append(scores[i])\n",
        "        if replace:\n",
        "            pass\n",
        "        else:\n",
        "          if best_samples: #make sure array is not empty before adding\n",
        "            self.data = np.concatenate((self.data, np.array(best_samples)), axis=0)\n",
        "        return best_samples, best_scores\n",
        "\n",
        "    def train(self, inputs, epochs, step_log=50, steps_per_epoch = 100, batch_size = BATCH_SIZE):\n",
        "        self.data = inputs\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        with open(BEST_PATH,'w') as f:\n",
        "          writer = csv.writer(f, delimiter=',')\n",
        "          writer.writerow([x for x in self.desired_features])\n",
        "        with open(AVERAGE_PATH,'w') as f:\n",
        "          writer = csv.writer(f, delimiter=',')\n",
        "          writer.writerow([x for x in self.desired_features])\n",
        "        for epoch in range(epochs):\n",
        "            dataset = self.create_dataset(self.data)\n",
        "\n",
        "            print(f'Epoch {epoch} / {epochs}')\n",
        "            \n",
        "            step = 0\n",
        "\n",
        "            for sample_batch in dataset:\n",
        "                G_loss = self.GAN.G_train_step()\n",
        "                D_loss, GP = self.GAN.D_train_step(sample_batch)\n",
        "\n",
        "                generated = self.GAN.generate_samples(number=BATCH_SIZE, decoded=False)\n",
        "                OneHot = OneHot_Seq(letter_type= TASK_TYPE)\n",
        "                decoded_generated = OneHot.onehot_to_seq(generated)\n",
        "                scores = self.get_scores(decoded_generated)\n",
        "                generated = tf.cast(generated, tf.float32)\n",
        "                best_samples,best_scores = self.add_samples(generated, scores)\n",
        "                if step % step_log == 0:\n",
        "                        with open(LOSS_PATH,'a') as f:\n",
        "                          writer = csv.writer(f, delimiter=',')\n",
        "                          writer.writerow([G_loss.numpy(),D_loss.numpy(),int((len(self.data) - len(inputs)) / len(self.data)*100)])\n",
        "                        print(f'\\tStep {step}\\n   \\tGenerator: {G_loss.numpy()}   Discriminator: {D_loss.numpy()}   Samples: {len(self.data)}')\n",
        "\n",
        "                        print('\\tBest scores per feature: ', end = ' ') \n",
        "                        score_per_feature = self.get_best_score_per_feature(scores)\n",
        "                        pprint = [f'{sc[0]}: {sc[1]}%' for sc in score_per_feature]\n",
        "                        with open(BEST_PATH,'a') as f:\n",
        "                          writer = csv.writer(f, delimiter=',')\n",
        "                          writer.writerow([sc[1] for sc in score_per_feature])\n",
        "                        print(*pprint, sep = ' ')\n",
        "\n",
        "                        print('\\tAverage scores per feature: ', end = ' ') \n",
        "                        score_per_feature = self.get_score_per_feature(scores)\n",
        "                        with open(AVERAGE_PATH,'a') as f:\n",
        "                          writer = csv.writer(f, delimiter=',')\n",
        "                          writer.writerow([sc[1] for sc in score_per_feature])\n",
        "                        pprint = [f'{sc[0]}: {sc[1]}%' for sc in score_per_feature]\n",
        "                        print(*pprint, sep = ' ')\n",
        "                    \n",
        "                if step == 100:\n",
        "                    break\n",
        "\n",
        "                step += 1\n",
        "            percent_fake = int((len(self.data) - len(inputs)) / len(self.data)*100)\n",
        "            print(f'\\tPercent of the fake samples in the discriminator: {percent_fake}%.')\n",
        "                \n",
        "                \n",
        "    def create_dataset(self, inputs):\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "        dataset = dataset.shuffle(inputs.shape[0], seed=0).batch(self.batch_size, drop_remainder=True)\n",
        "        return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnUMFn968oNU"
      },
      "source": [
        "# Run\n",
        "\n",
        "Loop writes to csv file located at path LOSS_PATH. Each row represents a log step. Columns are as follows:\n",
        "\n",
        "Generator Loss, Discriminator Loss, Samples\n",
        "\n",
        "It also writes average scores to AVERAGE_PATH with columns representing desired features (same for BEST_PATH with best scores)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HeVDNJ78rG7",
        "outputId": "897a59c7-67cd-401c-b38b-7597f7da46fa"
      },
      "source": [
        "real_sequences = prepare_dataset(path)\n",
        "path_G = '/content/gdrive/My Drive/CS496 final project/weights/weights_generator_243'\n",
        "path_D = '/content/gdrive/My Drive/CS496 final project/weights/weights_discriminator_243'\n",
        "\n",
        "ganfb = GAN_FBNet(path_G,path_D, features=['I'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 33633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooSVBVgtvRgz",
        "outputId": "08dbca8f-5a38-4a21-e241-05305c177874"
      },
      "source": [
        "print(\"SEQUENCES BEFORE TRAINING:\")\n",
        "print(ganfb.GAN.generate_samples(number = 3, decoded=True))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SEQUENCES BEFORE TRAINING:\n",
            "[['ATGGGTTCTGAGGCTTCGTAGGAGCAGGAGTCTGATGATTAGACGAAGAAGGATTCTGTTTTGGPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP'], ['ATGGGTGAGTATCAGGCTTTGAAGGATCAGGGGCATGAGCAGGGTTCTGAGGATCGTGGTAATGGGCAGGGTTCTGATACTTCTAAGGGTCGTGCTGCTCATGGTTTGGAGGGTTTGTTTGAGTATGCGTATTTGTCTTAGTAGATGATTAAGCAGAGTTTGPCPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP'], ['ATGGGTTTTGGGTAGTTGGGTATTTGTTTTGAGGATTATGGTAATGGTTTGAAGGGTTCTGGTTTGTATGGTTAGGTTGGGTGTGGGTCGTAGGTTTTGAAGGAGCATCGGGGTTAGTAGATTATTTAGPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVvyREmqnNKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf0be27-7923-4333-974c-65eb0ba9ed3b"
      },
      "source": [
        "import csv\n",
        "ganfb.train(real_sequences, epochs = 50, step_log = 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 50\n",
            "WARNING:tensorflow:Layer discriminator is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "\tStep 0\n",
            "   \tGenerator: 4.701275825500488   Discriminator: -1.131258487701416   Samples: 33633\n",
            "\tBest scores per feature:  I: 7%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 4.331458568572998   Discriminator: -1.3525761365890503   Samples: 33634\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: -1.3928693532943726   Discriminator: -1.2159347534179688   Samples: 33635\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 0.8399980664253235   Discriminator: -1.5080925226211548   Samples: 33635\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 2.162895679473877   Discriminator: -1.4865288734436035   Samples: 33637\n",
            "\tBest scores per feature:  I: 8%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 0.4713866710662842   Discriminator: -2.114938735961914   Samples: 33642\n",
            "\tBest scores per feature:  I: 7%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 1 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -2.807425022125244   Discriminator: -1.441819667816162   Samples: 33643\n",
            "\tBest scores per feature:  I: 19%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 6.473570823669434   Discriminator: -1.3578683137893677   Samples: 33643\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: -0.404100626707077   Discriminator: -0.9750926494598389   Samples: 33644\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 12.136205673217773   Discriminator: -0.6059666872024536   Samples: 33645\n",
            "\tBest scores per feature:  I: 7%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: -2.5065343379974365   Discriminator: -1.2300522327423096   Samples: 33650\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: -0.9970608949661255   Discriminator: 0.011613458395004272   Samples: 33652\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 2 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -2.9397735595703125   Discriminator: -0.9878127574920654   Samples: 33653\n",
            "\tBest scores per feature:  I: 11%\n",
            "\tAverage scores per feature:  I: 1%\n",
            "\tStep 20\n",
            "   \tGenerator: 3.4980921745300293   Discriminator: -0.9782055616378784   Samples: 33653\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 7.336450576782227   Discriminator: -1.2012608051300049   Samples: 33653\n",
            "\tBest scores per feature:  I: 9%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -7.433526992797852   Discriminator: -1.338545322418213   Samples: 33658\n",
            "\tBest scores per feature:  I: 12%\n",
            "\tAverage scores per feature:  I: 1%\n",
            "\tStep 80\n",
            "   \tGenerator: -5.065210342407227   Discriminator: 0.6011072993278503   Samples: 33662\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 4.08737850189209   Discriminator: -1.2293305397033691   Samples: 33663\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 3 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -0.6025362014770508   Discriminator: -1.5171685218811035   Samples: 33663\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 13.82730770111084   Discriminator: -1.1613763570785522   Samples: 33664\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 5.6311259269714355   Discriminator: -1.3316673040390015   Samples: 33668\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 0.39957910776138306   Discriminator: -1.0257177352905273   Samples: 33673\n",
            "\tBest scores per feature:  I: 11%\n",
            "\tAverage scores per feature:  I: 1%\n",
            "\tStep 80\n",
            "   \tGenerator: -1.8947285413742065   Discriminator: -1.2790069580078125   Samples: 33677\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: -5.144387245178223   Discriminator: -0.22702226042747498   Samples: 33680\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 4 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -1.5268546342849731   Discriminator: -1.2971241474151611   Samples: 33680\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 8.660725593566895   Discriminator: -1.261913537979126   Samples: 33682\n",
            "\tBest scores per feature:  I: 10%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 14.59611988067627   Discriminator: -0.51054447889328   Samples: 33684\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 9.397645950317383   Discriminator: -0.35060757398605347   Samples: 33691\n",
            "\tBest scores per feature:  I: 13%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 16.019115447998047   Discriminator: -0.2766096591949463   Samples: 33694\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 20.683856964111328   Discriminator: 0.16361305117607117   Samples: 33695\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 5 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 8.503475189208984   Discriminator: -0.5665075182914734   Samples: 33695\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 8.63426399230957   Discriminator: -1.2519289255142212   Samples: 33697\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 1.6547560691833496   Discriminator: -1.460348129272461   Samples: 33700\n",
            "\tBest scores per feature:  I: 7%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 6.04587459564209   Discriminator: -0.744157075881958   Samples: 33702\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 6.1198039054870605   Discriminator: -0.6615948677062988   Samples: 33702\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 5.120728015899658   Discriminator: -0.7680431008338928   Samples: 33704\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 6 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 0.4573679566383362   Discriminator: -1.299333930015564   Samples: 33704\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 3.7471868991851807   Discriminator: -1.163098931312561   Samples: 33705\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 1.9505776166915894   Discriminator: -1.4107513427734375   Samples: 33710\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 13.360678672790527   Discriminator: -2.2027628421783447   Samples: 33712\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 13.574117660522461   Discriminator: -1.2561274766921997   Samples: 33713\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 9.61793327331543   Discriminator: -1.2423433065414429   Samples: 33713\n",
            "\tBest scores per feature:  I: 8%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 7 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 7.313997268676758   Discriminator: -0.9558814167976379   Samples: 33714\n",
            "\tBest scores per feature:  I: 11%\n",
            "\tAverage scores per feature:  I: 1%\n",
            "\tStep 20\n",
            "   \tGenerator: -1.3638849258422852   Discriminator: -3.047755718231201   Samples: 33714\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 5.839249134063721   Discriminator: -0.964570164680481   Samples: 33717\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 3.4362096786499023   Discriminator: -0.9114841818809509   Samples: 33719\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 2.3925914764404297   Discriminator: -0.9437189698219299   Samples: 33721\n",
            "\tBest scores per feature:  I: 9%\n",
            "\tAverage scores per feature:  I: 1%\n",
            "\tStep 100\n",
            "   \tGenerator: -0.7305749654769897   Discriminator: -1.5403642654418945   Samples: 33726\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 8 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -3.8241119384765625   Discriminator: -1.224501609802246   Samples: 33726\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 1%\n",
            "\tStep 20\n",
            "   \tGenerator: 0.31249305605888367   Discriminator: -0.9425045251846313   Samples: 33728\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 10.765066146850586   Discriminator: -0.9431701898574829   Samples: 33730\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -2.0566039085388184   Discriminator: -1.13675856590271   Samples: 33731\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 1.3699092864990234   Discriminator: -1.5764656066894531   Samples: 33732\n",
            "\tBest scores per feature:  I: 7%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 7.54758358001709   Discriminator: -1.0253815650939941   Samples: 33735\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 9 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 5.309844970703125   Discriminator: -1.1086678504943848   Samples: 33735\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 2.493443012237549   Discriminator: -1.1280196905136108   Samples: 33740\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 2.0333049297332764   Discriminator: -0.9467771649360657   Samples: 33743\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -0.8801237940788269   Discriminator: -1.002928614616394   Samples: 33745\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 4.442468643188477   Discriminator: -0.8577539920806885   Samples: 33746\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 0.5909885168075562   Discriminator: -1.4401479959487915   Samples: 33749\n",
            "\tBest scores per feature:  I: 7%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 10 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 1.3639811277389526   Discriminator: -1.1444791555404663   Samples: 33749\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: -1.6537388563156128   Discriminator: -1.299961805343628   Samples: 33750\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 11.836498260498047   Discriminator: -0.8601210713386536   Samples: 33756\n",
            "\tBest scores per feature:  I: 12%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -3.1722636222839355   Discriminator: -1.4315168857574463   Samples: 33758\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: -5.206137180328369   Discriminator: -2.121462821960449   Samples: 33761\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: -0.755867063999176   Discriminator: -0.9365969896316528   Samples: 33765\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 11 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 0.3185504376888275   Discriminator: -1.0087300539016724   Samples: 33766\n",
            "\tBest scores per feature:  I: 11%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: -3.7987852096557617   Discriminator: -1.079792857170105   Samples: 33768\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 5.654644012451172   Discriminator: -0.5767287015914917   Samples: 33769\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -6.873373031616211   Discriminator: -0.8183091282844543   Samples: 33773\n",
            "\tBest scores per feature:  I: 9%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 5.073007583618164   Discriminator: -0.9790905117988586   Samples: 33778\n",
            "\tBest scores per feature:  I: 18%\n",
            "\tAverage scores per feature:  I: 1%\n",
            "\tStep 100\n",
            "   \tGenerator: -3.5613794326782227   Discriminator: -1.3307170867919922   Samples: 33781\n",
            "\tBest scores per feature:  I: 8%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 12 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -3.1622471809387207   Discriminator: -1.4037187099456787   Samples: 33782\n",
            "\tBest scores per feature:  I: 10%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: -6.71347188949585   Discriminator: 0.294916570186615   Samples: 33782\n",
            "\tBest scores per feature:  I: 8%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 7.251837730407715   Discriminator: -0.08536165952682495   Samples: 33784\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -0.9513317346572876   Discriminator: -0.9408621788024902   Samples: 33786\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: -1.1815600395202637   Discriminator: -1.5637848377227783   Samples: 33787\n",
            "\tBest scores per feature:  I: 10%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 3.670745611190796   Discriminator: -1.0418931245803833   Samples: 33789\n",
            "\tBest scores per feature:  I: 1%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 13 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 0.9726178646087646   Discriminator: -1.243462085723877   Samples: 33789\n",
            "\tBest scores per feature:  I: 7%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 1.374007225036621   Discriminator: -1.2546371221542358   Samples: 33791\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: -10.243656158447266   Discriminator: -1.4948694705963135   Samples: 33792\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -0.9087790846824646   Discriminator: -1.1544358730316162   Samples: 33794\n",
            "\tBest scores per feature:  I: 7%\n",
            "\tAverage scores per feature:  I: 1%\n",
            "\tStep 80\n",
            "   \tGenerator: 3.24116849899292   Discriminator: -0.9566447734832764   Samples: 33794\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 13.9483642578125   Discriminator: -1.532926321029663   Samples: 33794\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 14 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 20.459470748901367   Discriminator: -1.0585193634033203   Samples: 33794\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 1.4904290437698364   Discriminator: -1.1576452255249023   Samples: 33798\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 3.134983539581299   Discriminator: -0.9746772646903992   Samples: 33798\n",
            "\tBest scores per feature:  I: 10%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 8.083883285522461   Discriminator: -0.7933943271636963   Samples: 33803\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 3.37404727935791   Discriminator: -1.3944177627563477   Samples: 33806\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 1.9727904796600342   Discriminator: -1.5352360010147095   Samples: 33807\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 15 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 2.923922061920166   Discriminator: -1.399339199066162   Samples: 33807\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 8.64517879486084   Discriminator: -0.7689450979232788   Samples: 33807\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 10.42353630065918   Discriminator: -1.3390387296676636   Samples: 33809\n",
            "\tBest scores per feature:  I: 8%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 1.9971479177474976   Discriminator: -0.6306533813476562   Samples: 33809\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 4.163853168487549   Discriminator: -1.6779221296310425   Samples: 33812\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: -0.9551593065261841   Discriminator: -0.8619941473007202   Samples: 33814\n",
            "\tBest scores per feature:  I: 1%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 16 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 2.596251964569092   Discriminator: -1.3535609245300293   Samples: 33815\n",
            "\tBest scores per feature:  I: 16%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 1.343578577041626   Discriminator: -1.3528083562850952   Samples: 33819\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 2.4359829425811768   Discriminator: -0.8071909546852112   Samples: 33822\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -3.2771129608154297   Discriminator: -0.9360356330871582   Samples: 33823\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 1.4975454807281494   Discriminator: -1.1007375717163086   Samples: 33826\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 2.1081886291503906   Discriminator: -1.2893027067184448   Samples: 33827\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 17 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 5.333287239074707   Discriminator: -1.4870524406433105   Samples: 33827\n",
            "\tBest scores per feature:  I: 8%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 16.987525939941406   Discriminator: 1.1682089567184448   Samples: 33829\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: -0.1831468939781189   Discriminator: -0.9663746356964111   Samples: 33830\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 11.298234939575195   Discriminator: -1.5277959108352661   Samples: 33831\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 4.764337539672852   Discriminator: -0.9676405191421509   Samples: 33834\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: -8.90756607055664   Discriminator: -1.3373255729675293   Samples: 33837\n",
            "\tBest scores per feature:  I: 14%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 18 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -7.222219944000244   Discriminator: -0.9706884622573853   Samples: 33837\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 3.6023032665252686   Discriminator: -0.9667861461639404   Samples: 33839\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 0.3314092457294464   Discriminator: -1.1588436365127563   Samples: 33841\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 0.4298936128616333   Discriminator: -1.393845796585083   Samples: 33841\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 1.0861735343933105   Discriminator: -1.234724998474121   Samples: 33842\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: -7.155050277709961   Discriminator: -1.5263535976409912   Samples: 33844\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 19 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -7.523245334625244   Discriminator: -0.21907013654708862   Samples: 33844\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 1.5343751907348633   Discriminator: -1.1954766511917114   Samples: 33844\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 1.7571418285369873   Discriminator: -1.620686650276184   Samples: 33845\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 1.3564589023590088   Discriminator: -1.1946741342544556   Samples: 33848\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 4.610962867736816   Discriminator: -1.6070311069488525   Samples: 33849\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 2.808382987976074   Discriminator: -1.296931266784668   Samples: 33852\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 20 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 3.233562707901001   Discriminator: -1.4354665279388428   Samples: 33852\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 9.384919166564941   Discriminator: -1.0813109874725342   Samples: 33854\n",
            "\tBest scores per feature:  I: 9%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: -5.121112823486328   Discriminator: -1.4099340438842773   Samples: 33854\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -6.8608503341674805   Discriminator: -2.620373249053955   Samples: 33859\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 5.011340141296387   Discriminator: -1.360531210899353   Samples: 33862\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: -1.7417525053024292   Discriminator: -1.1224596500396729   Samples: 33864\n",
            "\tBest scores per feature:  I: 11%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 21 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 0.09443016350269318   Discriminator: -1.160845160484314   Samples: 33864\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: -4.840179443359375   Discriminator: -1.3737818002700806   Samples: 33866\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 0.7530884742736816   Discriminator: -1.5029950141906738   Samples: 33868\n",
            "\tBest scores per feature:  I: 10%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -0.4076640009880066   Discriminator: -1.170862078666687   Samples: 33869\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 1.7473809719085693   Discriminator: -1.2726471424102783   Samples: 33871\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: -1.1145057678222656   Discriminator: -1.337781548500061   Samples: 33874\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 22 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -2.3435044288635254   Discriminator: -1.589104175567627   Samples: 33875\n",
            "\tBest scores per feature:  I: 17%\n",
            "\tAverage scores per feature:  I: 1%\n",
            "\tStep 20\n",
            "   \tGenerator: -3.2851881980895996   Discriminator: -1.4671294689178467   Samples: 33876\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: -2.245596408843994   Discriminator: -1.940110206604004   Samples: 33877\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 7.862027645111084   Discriminator: -1.592361330986023   Samples: 33879\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: -0.03997313976287842   Discriminator: -1.4641692638397217   Samples: 33879\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: -0.9193440675735474   Discriminator: -1.6544439792633057   Samples: 33881\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 23 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 0.3929419219493866   Discriminator: -1.6509592533111572   Samples: 33881\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 0.46784085035324097   Discriminator: -1.5599699020385742   Samples: 33883\n",
            "\tBest scores per feature:  I: 1%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: -0.9624079465866089   Discriminator: -0.957883894443512   Samples: 33884\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 9.235910415649414   Discriminator: -0.9809867739677429   Samples: 33887\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 10.708836555480957   Discriminator: -1.3318101167678833   Samples: 33888\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 0.12434093654155731   Discriminator: -1.3407652378082275   Samples: 33889\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 24 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -2.288296699523926   Discriminator: -1.223044753074646   Samples: 33889\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 1.4911751747131348   Discriminator: -1.895230770111084   Samples: 33893\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 0.6148186922073364   Discriminator: -1.186049461364746   Samples: 33896\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -6.322782516479492   Discriminator: -0.9220705032348633   Samples: 33896\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: -3.438687324523926   Discriminator: -1.2712032794952393   Samples: 33899\n",
            "\tBest scores per feature:  I: 11%\n",
            "\tAverage scores per feature:  I: 1%\n",
            "\tStep 100\n",
            "   \tGenerator: 1.855173945426941   Discriminator: -1.614882230758667   Samples: 33901\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 25 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 0.9651269912719727   Discriminator: -1.9355204105377197   Samples: 33901\n",
            "\tBest scores per feature:  I: 9%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 2.4741322994232178   Discriminator: -1.7005937099456787   Samples: 33902\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 12.263765335083008   Discriminator: -0.4979352056980133   Samples: 33903\n",
            "\tBest scores per feature:  I: 9%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 4.594853401184082   Discriminator: -1.4922192096710205   Samples: 33905\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: -1.486299991607666   Discriminator: -1.036329984664917   Samples: 33905\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 2.1420705318450928   Discriminator: -1.4379020929336548   Samples: 33905\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 26 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 1.7265980243682861   Discriminator: -1.2136331796646118   Samples: 33905\n",
            "\tBest scores per feature:  I: 7%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 3.8684444427490234   Discriminator: -2.0816750526428223   Samples: 33906\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 0.6143941879272461   Discriminator: -1.1087074279785156   Samples: 33906\n",
            "\tBest scores per feature:  I: 1%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 3.605509042739868   Discriminator: -1.3078594207763672   Samples: 33906\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: -2.094423532485962   Discriminator: -1.5532203912734985   Samples: 33908\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: -3.757927656173706   Discriminator: -1.7365702390670776   Samples: 33910\n",
            "\tBest scores per feature:  I: 8%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 27 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: -4.96762752532959   Discriminator: -0.974933385848999   Samples: 33911\n",
            "\tBest scores per feature:  I: 11%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: -4.816240310668945   Discriminator: -1.6508300304412842   Samples: 33915\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 5.871119976043701   Discriminator: -1.717646598815918   Samples: 33922\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -1.6708292961120605   Discriminator: -1.2140048742294312   Samples: 33922\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: -0.3134007751941681   Discriminator: -1.5198311805725098   Samples: 33924\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 8.743922233581543   Discriminator: -1.7700543403625488   Samples: 33927\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 28 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 10.621100425720215   Discriminator: -1.293013572692871   Samples: 33927\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: -2.3222298622131348   Discriminator: -1.540495753288269   Samples: 33928\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 3.3056282997131348   Discriminator: -1.6685460805892944   Samples: 33929\n",
            "\tBest scores per feature:  I: 3%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: -1.2335011959075928   Discriminator: -1.4864733219146729   Samples: 33929\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: -7.566971302032471   Discriminator: -1.6199746131896973   Samples: 33929\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 5.645305633544922   Discriminator: -1.4661504030227661   Samples: 33930\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 29 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 7.098883628845215   Discriminator: -1.6746479272842407   Samples: 33930\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 1.218567132949829   Discriminator: -1.8893338441848755   Samples: 33933\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 4.831716537475586   Discriminator: -0.9904378652572632   Samples: 33933\n",
            "\tBest scores per feature:  I: 9%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 60\n",
            "   \tGenerator: 5.802190780639648   Discriminator: -0.44568943977355957   Samples: 33936\n",
            "\tBest scores per feature:  I: 2%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 80\n",
            "   \tGenerator: 7.5211896896362305   Discriminator: -2.294499158859253   Samples: 33937\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 100\n",
            "   \tGenerator: 3.816810131072998   Discriminator: -1.5121345520019531   Samples: 33942\n",
            "\tBest scores per feature:  I: 8%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tPercent of the fake samples in the discriminator: 0%.\n",
            "Epoch 30 / 50\n",
            "\tStep 0\n",
            "   \tGenerator: 7.119185924530029   Discriminator: -2.012552261352539   Samples: 33942\n",
            "\tBest scores per feature:  I: 4%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 20\n",
            "   \tGenerator: 6.326904773712158   Discriminator: -1.568122386932373   Samples: 33943\n",
            "\tBest scores per feature:  I: 5%\n",
            "\tAverage scores per feature:  I: 0%\n",
            "\tStep 40\n",
            "   \tGenerator: 0.32688108086586   Discriminator: -1.353214979171753   Samples: 33943\n",
            "\tBest scores per feature:  I: 6%\n",
            "\tAverage scores per feature:  I: 0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhu7jmcYWqol"
      },
      "source": [
        "samples = ganfb.GAN.generate_samples(number = 3, decoded=True)\n",
        "print(samples)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}